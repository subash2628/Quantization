{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.29411764705882354,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0029411764705882353,
      "grad_norm": 0.5884230136871338,
      "learning_rate": 0.0,
      "loss": 2.3205,
      "step": 1
    },
    {
      "epoch": 0.0058823529411764705,
      "grad_norm": 0.6134049296379089,
      "learning_rate": 4e-05,
      "loss": 2.4103,
      "step": 2
    },
    {
      "epoch": 0.008823529411764706,
      "grad_norm": 0.5908868312835693,
      "learning_rate": 8e-05,
      "loss": 2.3355,
      "step": 3
    },
    {
      "epoch": 0.011764705882352941,
      "grad_norm": 0.698172926902771,
      "learning_rate": 0.00012,
      "loss": 2.375,
      "step": 4
    },
    {
      "epoch": 0.014705882352941176,
      "grad_norm": 0.8418211340904236,
      "learning_rate": 0.00016,
      "loss": 2.2418,
      "step": 5
    },
    {
      "epoch": 0.01764705882352941,
      "grad_norm": 0.8506698608398438,
      "learning_rate": 0.0002,
      "loss": 2.0659,
      "step": 6
    },
    {
      "epoch": 0.020588235294117647,
      "grad_norm": 0.6932366490364075,
      "learning_rate": 0.00019789473684210526,
      "loss": 1.9168,
      "step": 7
    },
    {
      "epoch": 0.023529411764705882,
      "grad_norm": 0.5657410025596619,
      "learning_rate": 0.00019578947368421054,
      "loss": 1.7739,
      "step": 8
    },
    {
      "epoch": 0.026470588235294117,
      "grad_norm": 0.4966960549354553,
      "learning_rate": 0.0001936842105263158,
      "loss": 1.7152,
      "step": 9
    },
    {
      "epoch": 0.029411764705882353,
      "grad_norm": 0.519241452217102,
      "learning_rate": 0.00019157894736842104,
      "loss": 1.5551,
      "step": 10
    },
    {
      "epoch": 0.03235294117647059,
      "grad_norm": 0.5257972478866577,
      "learning_rate": 0.00018947368421052632,
      "loss": 1.5464,
      "step": 11
    },
    {
      "epoch": 0.03529411764705882,
      "grad_norm": 0.45367029309272766,
      "learning_rate": 0.0001873684210526316,
      "loss": 1.4467,
      "step": 12
    },
    {
      "epoch": 0.03823529411764706,
      "grad_norm": 0.42760801315307617,
      "learning_rate": 0.00018526315789473685,
      "loss": 1.3919,
      "step": 13
    },
    {
      "epoch": 0.041176470588235294,
      "grad_norm": 0.3538871109485626,
      "learning_rate": 0.0001831578947368421,
      "loss": 1.3715,
      "step": 14
    },
    {
      "epoch": 0.04411764705882353,
      "grad_norm": 0.30606749653816223,
      "learning_rate": 0.00018105263157894739,
      "loss": 1.244,
      "step": 15
    },
    {
      "epoch": 0.047058823529411764,
      "grad_norm": 0.3046785891056061,
      "learning_rate": 0.00017894736842105264,
      "loss": 1.2873,
      "step": 16
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.30542850494384766,
      "learning_rate": 0.0001768421052631579,
      "loss": 1.2486,
      "step": 17
    },
    {
      "epoch": 0.052941176470588235,
      "grad_norm": 0.29316970705986023,
      "learning_rate": 0.00017473684210526317,
      "loss": 1.2297,
      "step": 18
    },
    {
      "epoch": 0.05588235294117647,
      "grad_norm": 0.28508907556533813,
      "learning_rate": 0.00017263157894736842,
      "loss": 1.184,
      "step": 19
    },
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 0.27119895815849304,
      "learning_rate": 0.0001705263157894737,
      "loss": 1.2013,
      "step": 20
    },
    {
      "epoch": 0.061764705882352944,
      "grad_norm": 0.2644367516040802,
      "learning_rate": 0.00016842105263157895,
      "loss": 1.2148,
      "step": 21
    },
    {
      "epoch": 0.06470588235294118,
      "grad_norm": 0.25915661454200745,
      "learning_rate": 0.00016631578947368423,
      "loss": 1.1873,
      "step": 22
    },
    {
      "epoch": 0.06764705882352941,
      "grad_norm": 0.3005792200565338,
      "learning_rate": 0.00016421052631578948,
      "loss": 1.177,
      "step": 23
    },
    {
      "epoch": 0.07058823529411765,
      "grad_norm": 0.26732200384140015,
      "learning_rate": 0.00016210526315789473,
      "loss": 1.1932,
      "step": 24
    },
    {
      "epoch": 0.07352941176470588,
      "grad_norm": 0.2816459834575653,
      "learning_rate": 0.00016,
      "loss": 1.1821,
      "step": 25
    },
    {
      "epoch": 0.07647058823529412,
      "grad_norm": 0.2610591948032379,
      "learning_rate": 0.00015789473684210527,
      "loss": 1.1624,
      "step": 26
    },
    {
      "epoch": 0.07941176470588235,
      "grad_norm": 0.25575414299964905,
      "learning_rate": 0.00015578947368421052,
      "loss": 1.113,
      "step": 27
    },
    {
      "epoch": 0.08235294117647059,
      "grad_norm": 0.2648698687553406,
      "learning_rate": 0.0001536842105263158,
      "loss": 1.2028,
      "step": 28
    },
    {
      "epoch": 0.08529411764705883,
      "grad_norm": 0.2636127471923828,
      "learning_rate": 0.00015157894736842108,
      "loss": 1.1192,
      "step": 29
    },
    {
      "epoch": 0.08823529411764706,
      "grad_norm": 0.2569628357887268,
      "learning_rate": 0.00014947368421052633,
      "loss": 1.1493,
      "step": 30
    },
    {
      "epoch": 0.09117647058823529,
      "grad_norm": 0.26502522826194763,
      "learning_rate": 0.00014736842105263158,
      "loss": 1.1211,
      "step": 31
    },
    {
      "epoch": 0.09411764705882353,
      "grad_norm": 0.2693125009536743,
      "learning_rate": 0.00014526315789473686,
      "loss": 1.1513,
      "step": 32
    },
    {
      "epoch": 0.09705882352941177,
      "grad_norm": 0.28927960991859436,
      "learning_rate": 0.0001431578947368421,
      "loss": 1.1471,
      "step": 33
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.27183473110198975,
      "learning_rate": 0.00014105263157894736,
      "loss": 1.0763,
      "step": 34
    },
    {
      "epoch": 0.10294117647058823,
      "grad_norm": 0.28067871928215027,
      "learning_rate": 0.00013894736842105264,
      "loss": 1.0823,
      "step": 35
    },
    {
      "epoch": 0.10588235294117647,
      "grad_norm": 0.2824413478374481,
      "learning_rate": 0.0001368421052631579,
      "loss": 1.1112,
      "step": 36
    },
    {
      "epoch": 0.10882352941176471,
      "grad_norm": 0.2895243167877197,
      "learning_rate": 0.00013473684210526317,
      "loss": 1.0929,
      "step": 37
    },
    {
      "epoch": 0.11176470588235295,
      "grad_norm": 0.309924453496933,
      "learning_rate": 0.00013263157894736842,
      "loss": 1.0743,
      "step": 38
    },
    {
      "epoch": 0.11470588235294117,
      "grad_norm": 0.3175346553325653,
      "learning_rate": 0.0001305263157894737,
      "loss": 1.1207,
      "step": 39
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 0.34102368354797363,
      "learning_rate": 0.00012842105263157895,
      "loss": 1.0464,
      "step": 40
    },
    {
      "epoch": 0.12058823529411765,
      "grad_norm": 0.5112196803092957,
      "learning_rate": 0.0001263157894736842,
      "loss": 1.0997,
      "step": 41
    },
    {
      "epoch": 0.12352941176470589,
      "grad_norm": 0.3096373677253723,
      "learning_rate": 0.00012421052631578949,
      "loss": 1.0738,
      "step": 42
    },
    {
      "epoch": 0.1264705882352941,
      "grad_norm": 0.5169230103492737,
      "learning_rate": 0.00012210526315789474,
      "loss": 1.0586,
      "step": 43
    },
    {
      "epoch": 0.12941176470588237,
      "grad_norm": 0.31808388233184814,
      "learning_rate": 0.00012,
      "loss": 1.0777,
      "step": 44
    },
    {
      "epoch": 0.1323529411764706,
      "grad_norm": 0.4051235616207123,
      "learning_rate": 0.00011789473684210525,
      "loss": 1.0796,
      "step": 45
    },
    {
      "epoch": 0.13529411764705881,
      "grad_norm": 0.3467460572719574,
      "learning_rate": 0.00011578947368421053,
      "loss": 1.0218,
      "step": 46
    },
    {
      "epoch": 0.13823529411764707,
      "grad_norm": 0.3118881583213806,
      "learning_rate": 0.0001136842105263158,
      "loss": 1.0035,
      "step": 47
    },
    {
      "epoch": 0.1411764705882353,
      "grad_norm": 0.33690381050109863,
      "learning_rate": 0.00011157894736842105,
      "loss": 1.0323,
      "step": 48
    },
    {
      "epoch": 0.14411764705882352,
      "grad_norm": 0.3531959056854248,
      "learning_rate": 0.00010947368421052633,
      "loss": 1.0239,
      "step": 49
    },
    {
      "epoch": 0.14705882352941177,
      "grad_norm": 0.3440587520599365,
      "learning_rate": 0.00010736842105263158,
      "loss": 1.038,
      "step": 50
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.34634891152381897,
      "learning_rate": 0.00010526315789473685,
      "loss": 1.0151,
      "step": 51
    },
    {
      "epoch": 0.15294117647058825,
      "grad_norm": 0.3646716773509979,
      "learning_rate": 0.00010315789473684211,
      "loss": 1.0535,
      "step": 52
    },
    {
      "epoch": 0.15588235294117647,
      "grad_norm": 0.36254313588142395,
      "learning_rate": 0.00010105263157894738,
      "loss": 1.0284,
      "step": 53
    },
    {
      "epoch": 0.1588235294117647,
      "grad_norm": 0.3702599108219147,
      "learning_rate": 9.894736842105263e-05,
      "loss": 1.0453,
      "step": 54
    },
    {
      "epoch": 0.16176470588235295,
      "grad_norm": 0.3412645161151886,
      "learning_rate": 9.68421052631579e-05,
      "loss": 0.9939,
      "step": 55
    },
    {
      "epoch": 0.16470588235294117,
      "grad_norm": 0.3461454212665558,
      "learning_rate": 9.473684210526316e-05,
      "loss": 0.957,
      "step": 56
    },
    {
      "epoch": 0.1676470588235294,
      "grad_norm": 0.3653129041194916,
      "learning_rate": 9.263157894736843e-05,
      "loss": 1.0069,
      "step": 57
    },
    {
      "epoch": 0.17058823529411765,
      "grad_norm": 0.3528425395488739,
      "learning_rate": 9.052631578947369e-05,
      "loss": 0.9974,
      "step": 58
    },
    {
      "epoch": 0.17352941176470588,
      "grad_norm": 0.38364601135253906,
      "learning_rate": 8.842105263157894e-05,
      "loss": 1.019,
      "step": 59
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 0.3534761667251587,
      "learning_rate": 8.631578947368421e-05,
      "loss": 0.9997,
      "step": 60
    },
    {
      "epoch": 0.17941176470588235,
      "grad_norm": 0.3698074519634247,
      "learning_rate": 8.421052631578948e-05,
      "loss": 1.0273,
      "step": 61
    },
    {
      "epoch": 0.18235294117647058,
      "grad_norm": 0.39136165380477905,
      "learning_rate": 8.210526315789474e-05,
      "loss": 0.9969,
      "step": 62
    },
    {
      "epoch": 0.18529411764705883,
      "grad_norm": 0.4044947624206543,
      "learning_rate": 8e-05,
      "loss": 0.9801,
      "step": 63
    },
    {
      "epoch": 0.18823529411764706,
      "grad_norm": 0.38582363724708557,
      "learning_rate": 7.789473684210526e-05,
      "loss": 0.9754,
      "step": 64
    },
    {
      "epoch": 0.19117647058823528,
      "grad_norm": 0.3674963414669037,
      "learning_rate": 7.578947368421054e-05,
      "loss": 0.9634,
      "step": 65
    },
    {
      "epoch": 0.19411764705882353,
      "grad_norm": 0.36608949303627014,
      "learning_rate": 7.368421052631579e-05,
      "loss": 0.9494,
      "step": 66
    },
    {
      "epoch": 0.19705882352941176,
      "grad_norm": 0.39063361287117004,
      "learning_rate": 7.157894736842105e-05,
      "loss": 0.9959,
      "step": 67
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38502877950668335,
      "learning_rate": 6.947368421052632e-05,
      "loss": 0.9211,
      "step": 68
    },
    {
      "epoch": 0.20294117647058824,
      "grad_norm": 0.4083174467086792,
      "learning_rate": 6.736842105263159e-05,
      "loss": 0.9572,
      "step": 69
    },
    {
      "epoch": 0.20588235294117646,
      "grad_norm": 0.40551963448524475,
      "learning_rate": 6.526315789473685e-05,
      "loss": 0.9466,
      "step": 70
    },
    {
      "epoch": 0.2088235294117647,
      "grad_norm": 0.42111608386039734,
      "learning_rate": 6.31578947368421e-05,
      "loss": 0.9491,
      "step": 71
    },
    {
      "epoch": 0.21176470588235294,
      "grad_norm": 0.6280452013015747,
      "learning_rate": 6.105263157894737e-05,
      "loss": 0.9689,
      "step": 72
    },
    {
      "epoch": 0.21470588235294116,
      "grad_norm": 0.4178844392299652,
      "learning_rate": 5.894736842105263e-05,
      "loss": 0.9186,
      "step": 73
    },
    {
      "epoch": 0.21764705882352942,
      "grad_norm": 0.43056780099868774,
      "learning_rate": 5.68421052631579e-05,
      "loss": 0.9595,
      "step": 74
    },
    {
      "epoch": 0.22058823529411764,
      "grad_norm": 0.4578082859516144,
      "learning_rate": 5.4736842105263165e-05,
      "loss": 0.9553,
      "step": 75
    },
    {
      "epoch": 0.2235294117647059,
      "grad_norm": 0.4008558690547943,
      "learning_rate": 5.2631578947368424e-05,
      "loss": 0.9183,
      "step": 76
    },
    {
      "epoch": 0.22647058823529412,
      "grad_norm": 0.4541512131690979,
      "learning_rate": 5.052631578947369e-05,
      "loss": 0.9295,
      "step": 77
    },
    {
      "epoch": 0.22941176470588234,
      "grad_norm": 0.4571838676929474,
      "learning_rate": 4.842105263157895e-05,
      "loss": 0.9318,
      "step": 78
    },
    {
      "epoch": 0.2323529411764706,
      "grad_norm": 0.4181627929210663,
      "learning_rate": 4.6315789473684214e-05,
      "loss": 0.9289,
      "step": 79
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 0.444427490234375,
      "learning_rate": 4.421052631578947e-05,
      "loss": 0.9163,
      "step": 80
    },
    {
      "epoch": 0.23823529411764705,
      "grad_norm": 0.46918994188308716,
      "learning_rate": 4.210526315789474e-05,
      "loss": 0.9276,
      "step": 81
    },
    {
      "epoch": 0.2411764705882353,
      "grad_norm": 0.44294124841690063,
      "learning_rate": 4e-05,
      "loss": 0.9318,
      "step": 82
    },
    {
      "epoch": 0.24411764705882352,
      "grad_norm": 0.4460078179836273,
      "learning_rate": 3.789473684210527e-05,
      "loss": 0.9404,
      "step": 83
    },
    {
      "epoch": 0.24705882352941178,
      "grad_norm": 0.4624084532260895,
      "learning_rate": 3.578947368421053e-05,
      "loss": 0.8943,
      "step": 84
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4481983780860901,
      "learning_rate": 3.368421052631579e-05,
      "loss": 0.9145,
      "step": 85
    },
    {
      "epoch": 0.2529411764705882,
      "grad_norm": 0.4469178020954132,
      "learning_rate": 3.157894736842105e-05,
      "loss": 0.914,
      "step": 86
    },
    {
      "epoch": 0.25588235294117645,
      "grad_norm": 0.4633100926876068,
      "learning_rate": 2.9473684210526314e-05,
      "loss": 0.8986,
      "step": 87
    },
    {
      "epoch": 0.25882352941176473,
      "grad_norm": 0.4540143311023712,
      "learning_rate": 2.7368421052631583e-05,
      "loss": 0.9158,
      "step": 88
    },
    {
      "epoch": 0.26176470588235295,
      "grad_norm": 0.4555339515209198,
      "learning_rate": 2.5263157894736845e-05,
      "loss": 0.9094,
      "step": 89
    },
    {
      "epoch": 0.2647058823529412,
      "grad_norm": 0.4462202489376068,
      "learning_rate": 2.3157894736842107e-05,
      "loss": 0.8786,
      "step": 90
    },
    {
      "epoch": 0.2676470588235294,
      "grad_norm": 0.4726634621620178,
      "learning_rate": 2.105263157894737e-05,
      "loss": 0.9106,
      "step": 91
    },
    {
      "epoch": 0.27058823529411763,
      "grad_norm": 0.4791105389595032,
      "learning_rate": 1.8947368421052634e-05,
      "loss": 0.8917,
      "step": 92
    },
    {
      "epoch": 0.2735294117647059,
      "grad_norm": 0.4777922034263611,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 0.9157,
      "step": 93
    },
    {
      "epoch": 0.27647058823529413,
      "grad_norm": 0.47819069027900696,
      "learning_rate": 1.4736842105263157e-05,
      "loss": 0.8923,
      "step": 94
    },
    {
      "epoch": 0.27941176470588236,
      "grad_norm": 0.48183032870292664,
      "learning_rate": 1.2631578947368422e-05,
      "loss": 0.8861,
      "step": 95
    },
    {
      "epoch": 0.2823529411764706,
      "grad_norm": 0.44275352358818054,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.8828,
      "step": 96
    },
    {
      "epoch": 0.2852941176470588,
      "grad_norm": 0.47152894735336304,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.9082,
      "step": 97
    },
    {
      "epoch": 0.28823529411764703,
      "grad_norm": 0.47770845890045166,
      "learning_rate": 6.315789473684211e-06,
      "loss": 0.8968,
      "step": 98
    },
    {
      "epoch": 0.2911764705882353,
      "grad_norm": 0.46859484910964966,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.9397,
      "step": 99
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.47499319911003113,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.9038,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9089653466185728.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
